{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # To load numpy\n",
    "import pandas as pd # To load pandas\n",
    "import math # To calcuate mathematical problems\n",
    "import time #To calculate the time that take implement the algorithm\n",
    "from sklearn.model_selection import train_test_split  # for split arrays or matrices into random train and test subsets\n",
    "from sklearn.neighbors import KNeighborsClassifier    # here we are importing KNeighborsClassifie from sklearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics   # importing metrics from sklearn to findout the performance measures.\n",
    "import sklearn.preprocessing as preprocessing #Importing preprocess algorithm\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load USPS Dataset from HDF5 file\n",
    "import h5py\n",
    "usps=\"usps.h5\"\n",
    "with h5py.File(usps, 'r') as hf: #the dataset fetch in reading format\n",
    "        train = hf.get('train')\n",
    "        x_train = train.get('data')[:]\n",
    "        y_train = train.get('target')[:]\n",
    "        test = hf.get('test')\n",
    "        x_test = test.get('data')[:]\n",
    "        y_test = test.get('target')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.1645, 0.086 , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       ...,\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 4, ..., 3, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 3, ..., 4, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (5468, 256)\n",
      "Y_train: (5468,)\n",
      "X_test:  (2007, 256)\n",
      "Y_test:  (2007,)\n",
      "X_cal: (1823, 256)\n",
      "Y_cal: (1823,)\n",
      "Training set Size: 5468\n",
      "Test Set Size: 2007\n",
      "Calibration Set Size: 1823\n"
     ]
    }
   ],
   "source": [
    "x_train_p, x_cal, y_train_p, y_cal = train_test_split(x_train, y_train, random_state=0)\n",
    "print('X_train: ' + str(x_train_p.shape))\n",
    "print('Y_train: ' + str(y_train_p.shape))\n",
    "print('X_test:  '  + str(x_test.shape))\n",
    "print('Y_test:  '  + str(y_test.shape))\n",
    "print('X_cal: ' + str(x_cal.shape))\n",
    "print('Y_cal: ' + str(y_cal.shape))\n",
    "print(\"Training set Size:\", len(x_train_p))\n",
    "print(\"Test Set Size:\",len(x_test))\n",
    "print(\"Calibration Set Size:\",len(x_cal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result of  Nearest Neighbour Algorithm for classsification is \n",
      "\n",
      "\n",
      "Prediction time  is:  6.88 seconds\n",
      "Accuracy: 0.9431988041853513\n",
      "Error Rate is:  0.05680119581464871\n"
     ]
    }
   ],
   "source": [
    "print(\" Result of  Nearest Neighbour Algorithm for classsification is \\n\")\n",
    "start = time.time()\n",
    "nn_class = KNeighborsClassifier(n_neighbors=1)\n",
    "nn_class.fit(x_train_p,y_train_p)\n",
    "y_pred = nn_class.predict(x_test)\n",
    "print('\\nPrediction time  is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "print('Accuracy:',nn_class.score(x_test,y_test))\n",
    "print(\"Error Rate is: \",1-nn_class.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result of  Nearest Neighbour Algorithm for Regression is \n",
      "\n",
      "\n",
      "Prediction time  is:  4.64 seconds\n",
      "Accuracy: 0.8980694861335402\n",
      "Error Rate is:  0.1019305138664598\n"
     ]
    }
   ],
   "source": [
    "print(\" Result of  Nearest Neighbour Algorithm for Regression is \\n\")\n",
    "start = time.time()\n",
    "nn_reg = KNeighborsRegressor(n_neighbors=1)\n",
    "nn_reg.fit(x_train_p,y_train_p)\n",
    "y_pred = nn_class.predict(x_test)\n",
    "print('\\nPrediction time  is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "print('Accuracy:',nn_reg.score(x_test,y_test))\n",
    "print(\"Error Rate is: \",1-nn_reg.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Result of  Nearest Neighbour Algorithm for Unsupervised learning is \n",
      "\n",
      "\n",
      "Prediction time  is:  0.30 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\" Result of  Nearest Neighbour Algorithm for Unsupervised learning is \\n\")\n",
    "start = time.time()\n",
    "nn_model = NearestNeighbors(n_neighbors=1)\n",
    "nn_model.fit(x_train_p,x_train_p)\n",
    "print('\\nPrediction time  is: ',\"%.2f\" %(time.time() - start),\"seconds\")\n",
    "#print('Accuracy:',nn_model.score(x_test,y_test))\n",
    "#print(\"Error Rate is: \",1-nn_model.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_variables(x_train_p,y_train_p,x_test,k):\n",
    "    nn_model = NearestNeighbors(n_neighbors=k+1)\n",
    "    score=np.zeros(len(x_train_p)+1)\n",
    "    p_values=np.zeros((len(x_test),len(set(y_train_p))))\n",
    "    prediction=np.zeros(len(x_test))\n",
    "    confidence=np.zeros(len(x_test))\n",
    "    credibility=np.zeros(len(x_test))\n",
    "    sum_p=0\n",
    "    return nn_model, score, p_values, prediction, confidence, credibility, sum_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_induc_conf_predictor(x_train_p,y_train_p,x_cal,y_cal,x_test,y_test,k, smooth ):\n",
    "    #Initialize variables for storage\n",
    "    nn_model, score, p_values, prediction, confidence, credibility, sum_p = \\\n",
    "    set_variables(x_train_p,y_train_p,x_test,k)\n",
    "    #score=[]\n",
    "    #Calculate the non-conformity scores for the calibration set\n",
    "    #For each label take all samples with that label and use it in calculating distance to the nearest sample of the\n",
    "    #same and different labels\n",
    "    for n in set(y_train_p):\n",
    "        #Get samples in the training set proper with label n\n",
    "        same_sample_1=x_train_p[y_train_p==n]\n",
    "        print(same_sample_1)\n",
    "        #Get samples in calibration set with label n\n",
    "        same_sample_2=x_cal[y_cal==n]\n",
    "        #print (same_sample_2)\n",
    "        #Fit nearest neighbours to the training set proper samples with the same label\n",
    "        nn_model.fit(same_sample_1)\n",
    "       # print(neigh.fit(same_sample_1))\n",
    "        #Get distances for calibration set samples to samples of the same label\n",
    "        #print(nn_model.kneighbors(same_sample_2)[0][:,1])\n",
    "        same_scores=nn_model.kneighbors(same_sample_2)[0][:,1]\n",
    "        #Get samples in the training set proper with a different label to n      d\n",
    "        diff_sample_1=x_train_p[y_train_p!=n]\n",
    "        #Fit nearest neighbours to the training set proper samples with the same label\n",
    "        nn_model.fit(diff_sample_1)\n",
    "        diff_scores=nn_model.kneighbors(same_sample_2)[0][:,0]\n",
    "        score.numpy.extend(same_scores/diff_scores)\n",
    "    #Loop through test samples\n",
    "   \n",
    "    for i in range(len(x_test)):\n",
    "        for j in set(y_train_p): #Test all possible labels\n",
    "            nn_model.fit(x_train_p[y_train_p==j])\n",
    "            NN_dist_s=nn_model.kneighbors([x_test[i]])[0][0][1]\n",
    "            nn_model.fit(x_train_p[y_train_p!=j])\n",
    "            NN_dist_d=np.sum(nn_model.kneighbors([x_test[i]])[0][0][0])\n",
    "            score_extend=np.append(score,NN_dist_s/NN_dist_d)\n",
    "        #Calculate p-values of test sample\n",
    "            if smooth == True:\n",
    "                tau=np.random.uniform()\n",
    "                p_values[i][j]=(np.sum(score_extend>score_extend[-1])+(tau*(np.sum(score_extend==score_extend[-1]))))/len(score_extend)\n",
    "\n",
    "            else:\n",
    "                p_values[i][j]=np.mean(score_extend>=score_extend[-1])\n",
    "    #print(p_values)         \n",
    "    #Use p-values of test sample to calculate various measures\n",
    "        prediction[i]=int(np.argmax(p_values[i]))\n",
    "    #print(prediction)\n",
    "        confidence[i]=1- p_values[i][np.argsort(p_values[i])[-2]]\n",
    "        credibility[i]=np.max(p_values[i])\n",
    "        sum_p_values = sum_p_values + np.sum(p_values[i]) - p_values[i][y_test[i]]\n",
    "    false_p_value=sum_p_values/(2*len(x_test))\n",
    "    return prediction, confidence, credibility, p_values, false_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-8c2630bbffb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mone_NN_pred_induc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknn_induc_conf_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_p\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_cal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_cal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--- %s seconds ---\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Inductive SVM Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_NN_pred_induc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Inductive SVM Avg False p-value: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_NN_pred_induc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-43b399a3584d>\u001b[0m in \u001b[0;36mknn_induc_conf_predictor\u001b[1;34m(x_train_p, y_train_p, x_cal, y_cal, x_test, y_test, k, smooth)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff_sample_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdiff_scores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_sample_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msame_scores\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdiff_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;31m#Loop through test samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "one_NN_pred_induc=knn_induc_conf_predictor(x_train_p,y_train_p,x_cal,y_cal,x_test,y_test,1, False )\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Inductive SVM Accuracy: \", np.mean(one_NN_pred_induc[0]==y_test))\n",
    "print(\"Inductive SVM Avg False p-value: \", one_NN_pred_induc[4])\n",
    "print(\"Inductive Avg Credibility: \",np.mean(one_NN_pred_induc[2]))\n",
    "print(\"Inductive Avg Confidence: \",np.mean(one_NN_pred_induc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
