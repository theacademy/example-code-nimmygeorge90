{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import libraries \n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load USPS Dataset\n",
    "import h5py\n",
    "path=\"usps.h5\"\n",
    "with h5py.File(path, 'r') as usps_data:\n",
    "    train = usps_data.get('train')\n",
    "    x_train = train.get('data')[:]\n",
    "    y_train = train.get('target')[:]\n",
    "    test = usps_data.get('test')\n",
    "    x_test = test.get('data')[:]\n",
    "    y_test = test.get('target')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.1645, 0.086 , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       ...,\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.    , 0.    , ..., 0.    , 0.    , 0.    ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 4, ..., 3, 0, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 3, ..., 4, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usps_x: (9298, 256)\n",
      "usps_y: (9298,)\n"
     ]
    }
   ],
   "source": [
    "#Concatenate training and test set\n",
    "usps_x=np.row_stack((x_train,x_test))\n",
    "usps_y=np.append(y_train,y_test)\n",
    "print('usps_x: ' + str(usps_x.shape)) #Total size of the dataset when we concatenate both training and test set\n",
    "print('usps_y: ' + str(usps_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7438, 256)\n",
      "Y_train: (7438,)\n",
      "X_test:  (1860, 256)\n",
      "Y_test:  (1860,)\n",
      "Training  Size: 7438\n",
      "Test dataset Size: 1860\n"
     ]
    }
   ],
   "source": [
    "#Initially complete dataset split into 2,the training set size=80% and the rest are test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(usps_x, usps_y, random_state=0,train_size=0.80)\n",
    "print('X_train: ' + str(x_train.shape))\n",
    "print('Y_train: ' + str(y_train.shape))\n",
    "print('X_test:  '  + str(x_test.shape))\n",
    "print('Y_test:  '  + str(y_test.shape))\n",
    "print(\"Training  Size:\", len(x_train))\n",
    "print(\"Test dataset Size:\",len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_variables(x_train,y_train,x_test,y_test,k): #Function to initialze the variables\n",
    "    nn_model = NearestNeighbors(n_neighbors=k+1) # Initialize nearest neighbour model\n",
    "    score=np.zeros(len(x_train)+1)\n",
    "    p_values=np.zeros((len(x_test),len(set(y_train))))\n",
    "    pred=np.zeros(len(x_test))\n",
    "    conf=np.zeros(len(x_test))\n",
    "    cred=np.zeros(len(x_test))\n",
    "    sum_p=0\n",
    "    return nn_model, score, p_values, pred, conf, cred, sum_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(extend_train_x,extend_train_y,new_data_train,new_target_train,nn_model,n): #function to calcuate non conformity score\n",
    "    same_dist_train=extend_train_x[extend_train_y==n]\n",
    "    same_dist_cal=new_data_train[new_target_train==n]\n",
    "    nn_model.fit(same_dist_train)\n",
    "    ncs_same=nn_model.kneighbors(same_dist_cal)[0][:,1]\n",
    "    diff_dist_train=extend_train_x[extend_train_y!=n]\n",
    "    nn_model.fit(diff_dist_train)\n",
    "    ncs_diff=nn_model.kneighbors(same_dist_cal)[0][:,0]\n",
    "    result_score=ncs_same/ncs_diff\n",
    "    return result_score,nn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Implement 1NN Transductive conformal Prediction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def tcp(x_train,y_train,x_test,y_test,k):\n",
    "    #Set variables\n",
    "    nn_model, score, p_values, pred, conf, cred, sum_p = \\\n",
    "    set_variables(x_train,y_train,x_test,y_test,k)\n",
    "    #Loop through test samples\n",
    "    for i in range(len(x_test)):\n",
    "        extend_train_x=np.row_stack((x_train,x_test[i])) #Create new dataset which is the training set + the test sample\n",
    "        for j in set(y_train): #Test all possible labels\n",
    "            extend_train_y=np.append(y_train,j)#Extend labels with test sample\n",
    "            conf_scores=[]\n",
    "            new_x_train=extend_train_x[:len(extend_train_x)-1]\n",
    "            new_y_train=extend_train_y[:len(extend_train_y)-1]\n",
    "            for n in range(10):\n",
    "                # calling Function calculate scores\n",
    "                result_score,nn_model=\\\n",
    "                calculate_score(extend_train_x,extend_train_y,new_x_train,new_y_train,nn_model,n)\n",
    "                conf_scores.extend(result_score)\n",
    "            data_sample=extend_train_x[-1]\n",
    "            target_sample=extend_train_y[-1]\n",
    "            nn_model.fit(extend_train_x[extend_train_y==target_sample])# Fit the model\n",
    "            same_dist_test=nn_model.kneighbors([data_sample])[0][0][1]\n",
    "            nn_model.fit(extend_train_x[extend_train_y!=target_sample])\n",
    "            diff_dist_test=np.sum(nn_model.kneighbors([data_sample])[0][0][0])\n",
    "            conf_scores.append(same_dist_test/diff_dist_test)# cacluate non conformity score of test set\n",
    "            p_values[i][j]=np.mean(conf_scores>=conf_scores[-1])#Calculate p-values of test sample\n",
    "        pred[i]=int(np.argmax(p_values[i]))#Use p-values of test sample to calculate various measures calculate prediction\n",
    "        conf[i]=1- p_values[i][np.argsort(p_values[i])[-2]] #calculate Confidence\n",
    "        cred[i]=np.max(p_values[i])#calculate credibility\n",
    "        sum_p = sum_p + np.sum(p_values[i]) - p_values[i][y_test[i]]#calculate sum of p_value\n",
    "    false_p_value=sum_p/(2*len(x_test))#calculate false p_value\n",
    "    return pred, conf, cred, false_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total run time 3632.5689861774445 seconds \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pred, conf, cred, false_p_value = \\\n",
    "tcp(x_train,y_train,x_test[0:10],y_test[0:10],1 )\n",
    "print(\"Total run time %s seconds \" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy:  0.9\n",
      "Avg False p-value:  0.011090200295738683\n",
      "Confidence:  0.99853474929426\n",
      "Credibility:  0.4774297620647937\n"
     ]
    }
   ],
   "source": [
    "print(\" Accuracy: \", np.mean(pred==y_test[0:10]))\n",
    "print(\"Avg False p-value: \", false_p_value)\n",
    "print(\"Confidence: \",np.mean(conf))\n",
    "print(\"Credibility: \",np.mean(cred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
